{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\georg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape DataFrame:  (2772, 5)\n",
      "Data size:  2772\n",
      "Dropando NaN\n",
      "Data size:  2683\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>speakers</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-26</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>European Parliament plenary debate on the ECB ...</td>\n",
       "      <td>Speech by Christine Lagarde, President of the ...</td>\n",
       "      <td>SPEECH   European Parliament plenary debate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-02-15</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>Hearing of the Committee on Economic and Monet...</td>\n",
       "      <td>Speech by Christine Lagarde, President of the ...</td>\n",
       "      <td>SPEECH  Hearing of the Committee on Economic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>Governance at a turning point</td>\n",
       "      <td>Speech by Christine Lagarde, President of the ...</td>\n",
       "      <td>SPEECH  Governance at a turning point   Spee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>Welcome address at the fifth ECB Forum on Bank...</td>\n",
       "      <td>Speech by Christine Lagarde, President of the ...</td>\n",
       "      <td>SPEECH  Welcome address at the fifth ECB For...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023-11-27</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>Hearing of the Committee on Economic and Monet...</td>\n",
       "      <td>Speech by Christine Lagarde, President of the ...</td>\n",
       "      <td>SPEECH  Hearing of the Committee on Economic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date           speakers  \\\n",
       "0   2024-02-26  Christine Lagarde   \n",
       "4   2024-02-15  Christine Lagarde   \n",
       "18  2023-12-04  Christine Lagarde   \n",
       "19  2023-11-30  Christine Lagarde   \n",
       "21  2023-11-27  Christine Lagarde   \n",
       "\n",
       "                                                title  \\\n",
       "0   European Parliament plenary debate on the ECB ...   \n",
       "4   Hearing of the Committee on Economic and Monet...   \n",
       "18                      Governance at a turning point   \n",
       "19  Welcome address at the fifth ECB Forum on Bank...   \n",
       "21  Hearing of the Committee on Economic and Monet...   \n",
       "\n",
       "                                             subtitle  \\\n",
       "0   Speech by Christine Lagarde, President of the ...   \n",
       "4   Speech by Christine Lagarde, President of the ...   \n",
       "18  Speech by Christine Lagarde, President of the ...   \n",
       "19  Speech by Christine Lagarde, President of the ...   \n",
       "21  Speech by Christine Lagarde, President of the ...   \n",
       "\n",
       "                                             contents  \n",
       "0     SPEECH   European Parliament plenary debate ...  \n",
       "4     SPEECH  Hearing of the Committee on Economic...  \n",
       "18    SPEECH  Governance at a turning point   Spee...  \n",
       "19    SPEECH  Welcome address at the fifth ECB For...  \n",
       "21    SPEECH  Hearing of the Committee on Economic...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"all_ECB_speeches.csv\", sep=\"|\", encoding=\"utf-8\")\n",
    "print(\"Shape DataFrame: \", data.shape)\n",
    "print(\"Data size: \", data.shape[0])\n",
    "data_drop_nan = data.dropna(subset=data.columns)\n",
    "data.dropna(subset=data.columns, inplace=True)\n",
    "print(\"Dropando NaN\")\n",
    "print(\"Data size: \", data_drop_nan.shape[0] )\n",
    "data = data[data[\"speakers\"] == \"Christine Lagarde\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = data.loc[0, 'contents'].split(\"2024 \")[1]\n",
    "tokenized_text = word_tokenize(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "sentim_analyzer = SentimentAnalyzer()\n",
    "all_words_neg = sentim_analyzer.all_words(mark_negation(tokenized_text))\n",
    "unigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg, min_freq=4)\n",
    "print(len(unigram_feats))\n",
    "sentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m training_set \u001b[38;5;241m=\u001b[39m sentim_analyzer\u001b[38;5;241m.\u001b[39mapply_features(tokenized_text)\n\u001b[0;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m NaiveBayesClassifier\u001b[38;5;241m.\u001b[39mtrain\n\u001b[1;32m----> 3\u001b[0m classifier \u001b[38;5;241m=\u001b[39m \u001b[43msentim_analyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\georg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\sentiment\\sentiment_analyzer.py:179\u001b[0m, in \u001b[0;36mSentimentAnalyzer.train\u001b[1;34m(self, trainer, training_set, save_classifier, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03mTrain classifier on the training set, optionally saving the output in the\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03mfile specified by `save_classifier`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m:rtype:\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining classifier\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_classifier:\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_file(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier, save_classifier)\n",
      "File \u001b[1;32mc:\\Users\\georg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\classify\\naivebayes.py:210\u001b[0m, in \u001b[0;36mNaiveBayesClassifier.train\u001b[1;34m(cls, labeled_featuresets, estimator)\u001b[0m\n\u001b[0;32m    206\u001b[0m fnames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m    208\u001b[0m \u001b[38;5;66;03m# Count up how many times each feature value occurred, given\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;66;03m# the label and featurename.\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m featureset, label \u001b[38;5;129;01min\u001b[39;00m labeled_featuresets:\n\u001b[0;32m    211\u001b[0m     label_freqdist[label] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fname, fval \u001b[38;5;129;01min\u001b[39;00m featureset\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;66;03m# Increment freq(fval|label, fname)\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "training_set = sentim_analyzer.apply_features(tokenized_text)\n",
    "trainer = NaiveBayesClassifier.train\n",
    "classifier = sentim_analyzer.train(trainer, training_set)\n",
    "# acho que falta as labels de \"obj, subj\" que tem no exemplo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
